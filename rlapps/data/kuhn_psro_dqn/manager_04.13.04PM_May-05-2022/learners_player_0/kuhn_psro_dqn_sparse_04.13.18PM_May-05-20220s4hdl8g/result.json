{"episode_reward_max": 0.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.0, "episode_len_mean": 2.0, "episode_media": {}, "episodes_this_iter": 512, "policy_reward_min": {"metanash": -1.0, "best_response": -1.0}, "policy_reward_max": {"metanash": 1.0, "best_response": 1.0}, "policy_reward_mean": {"metanash": -0.932, "best_response": 0.932}, "custom_metrics": {}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24772722305068115, "mean_inference_ms": 0.4365818487066631, "mean_action_processing_ms": 0.02751966454656614, "mean_env_wait_ms": 0.08315785927990875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 25600, "timesteps_this_iter": 4096, "agent_timesteps_total": 25600, "timers": {"load_time_ms": 0.139, "load_throughput": 29447838.848, "learn_time_ms": 6.834, "learn_throughput": 599370.244, "update_time_ms": 1.317}, "info": {"learner": {"best_response": {"learner_stats": {"allreduce_latency": 0.0}, "loss": 0.23689435422420502, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 4096.0}}, "num_steps_sampled": 25600, "num_agent_steps_sampled": 25600, "num_steps_trained": 40960, "num_steps_trained_this_iter": 4096, "num_agent_steps_trained": 81920, "last_target_update_ts": 16384, "num_target_updates": 1}, "done": false, "episodes_total": 12800, "training_iteration": 10, "trial_id": "default", "experiment_id": "1faf6e23d3604a928b65056b6ad4cbe9", "date": "2022-05-05_16-13-29", "timestamp": 1651738409, "time_this_iter_s": 0.4289560317993164, "time_total_s": 9.283754825592041, "pid": 2850530, "hostname": "sjtu-marl1", "node_ip": "192.168.2.51", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 256, "batch_mode": "truncate_episodes", "gamma": 1.0, "lr": 0.01, "train_batch_size": 4096, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [128], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "PokerMultiAgentEnv", "observation_space": null, "action_space": null, "env_config": {"version": "kuhn_poker", "fixed_players": true}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.train_psro_best_response.<locals>.P2SROPreAndPostEpisodeCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "<class 'rlapps.rllib_tools.valid_actions_epsilon_greedy.ValidActionsEpsilonGreedy'>", "initial_epsilon": 0.2, "final_epsilon": 0.001, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 256, "batch_mode": "truncate_episodes", "gamma": 1.0, "lr": 0.01, "train_batch_size": 4096, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [128], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "PokerMultiAgentEnv", "observation_space": null, "action_space": null, "env_config": {"version": "kuhn_poker", "fixed_players": true}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class '__main__.train_psro_best_response.<locals>.P2SROPreAndPostEpisodeCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "<class 'rlapps.rllib_tools.valid_actions_epsilon_greedy.ValidActionsEpsilonGreedy'>", "initial_epsilon": 0.2, "final_epsilon": 0.001, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 1000, "min_time_s_per_reporting": 0, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0.0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"metanash": ["<class 'ray.rllib.policy.policy_template.SimpleQPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (11,), float32)", "Discrete(2)", {"explore": false}], "best_response": ["<class 'ray.rllib.policy.policy_template.SimpleQPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (11,), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function train_psro_best_response.<locals>.select_policy at 0x7ffabe7d6550>", "policies_to_train": ["best_response"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 10000, "buffer_size": 200000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": null, "learning_starts": 16000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.0, "prioritized_replay_beta": 0.0, "final_prioritized_replay_beta": 0.0, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 0.0, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "keep_per_episode_custom_metrics": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 1000, "min_time_s_per_reporting": 0, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0.0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"metanash": ["<class 'ray.rllib.policy.policy_template.SimpleQPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (11,), float32)", "Discrete(2)", {"explore": false}], "best_response": ["<class 'ray.rllib.policy.policy_template.SimpleQPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (11,), float32)", "Discrete(2)", {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function train_psro_best_response.<locals>.select_policy at 0x7ffabe7d6550>", "policies_to_train": ["best_response"], "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "disable_env_checking": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 0, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "target_network_update_freq": 10000, "buffer_size": 200000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": null, "learning_starts": 16000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": false, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.0, "prioritized_replay_beta": 0.0, "final_prioritized_replay_beta": 0.0, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 0.0, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 9.283754825592041, "timesteps_since_restore": 40960, "iterations_since_restore": 10, "warmup_time": 1.4784553050994873, "perf": {"cpu_util_percent": 7.4, "ram_util_percent": 4.6}, "scenario_name": "kuhn_psro_dqn"}
